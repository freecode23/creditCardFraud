{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing and Training Data<a id='Pre-Processing_and_Training_Data'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Contents<a id='Contents'></a>\n",
    "* [1. Imports](#1._Imports)\n",
    "* [2. Load The Data](#2._Load_Data)\n",
    "* [3. Train/Test Split](#3._Train/Test_Split)\n",
    "* [4. Scaling](#4._Scaling)\n",
    "* [5. Logistic Model](#5._Logistic_Model)\n",
    "    * [5.1 Train Test](#5.1_Train_test)\n",
    "    * [5.2 Tuning](#5.2_Tuning)\n",
    "    * [5.3 Pipeline](#5.3_Pipeline)\n",
    "    * [5.4 Refining model using GridSearchCV](#5.4_Refine)\n",
    "        * [5.4.1 Create Grid](#5.4.1_Create_Grid)\n",
    "        * [5.4.2 Summarize Result](#5.4.2_Summarize_Result)\n",
    "        * [5.4.3 Check best params](#5.4.3_Check_best_params)\n",
    "    * [5.5 Recreate_model_with_best_param](#5.5_Recreate_model)\n",
    "    * [5.6 Confusion matrix with best param](#5.6_Confusion_matrix)\n",
    "    * [5.7 ROC/AUC Score](#5.7_ROC_AUC)\n",
    "* [6. Random Forest Model](#6._Logistic_Model)\n",
    "    * [6.1 Train Test](#6.1_Train_test)\n",
    "    * [6.2 Pipeline](#6.2_Pipeline)\n",
    "    * [6.3 Refining model using GridSearchCV](#6.4_Refine)\n",
    "        * [6.3.1 Create Grid](#6.3.1_Create_Grid)\n",
    "        * [6.3.2 Summarize Result](#6.3.2_Summarize_Result)\n",
    "        * [6.3.3 Check best params](#6.3.3_Check_best_params)\n",
    "    * [6.4 Recreate_model_with_best_param](#6.4_Recreate_model)\n",
    "    * [6.5 ROC/AUC Score](#6.5_ROC_AUC)\n",
    "* [7. XG_Boost Model](#7._XG_Boost_Model)\n",
    "    * [7.1 Train Test](#7.1_Train_test)\n",
    "    * [7.2 Refining model using GridSearchCV](#7.2_Refine)\n",
    "        * [7.2.1 Create Grid](#7.2.1_Create_Grid)\n",
    "        * [7.2.2 Check best params](#7.2.2_Check_best_params)\n",
    "    * [7.3 Recreate_model_with_best_param](#7.3_Recreate_model)\n",
    "    * [7.4 ROC/AUC Score](#7.4_ROC_AUC)\n",
    "* [8.Learning Curve](#8._Learning_Curve)  \n",
    "* [9.Save Model](#9._Save_Model)  \n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using :\n",
    "1. Logistic Regression\n",
    "2. Random Forest\n",
    "3. XG Boost model\n",
    "to predict whether or not a transaction is fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports <a id='1._Imports'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, recall_score\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load The Data<a id='2._Load_Data'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(731560, 27)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>creditLimit</th>\n",
       "      <td>50000</td>\n",
       "      <td>20000</td>\n",
       "      <td>10000</td>\n",
       "      <td>2500</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availableMoney</th>\n",
       "      <td>50000</td>\n",
       "      <td>20000</td>\n",
       "      <td>10000</td>\n",
       "      <td>2500</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merchantName</th>\n",
       "      <td>Washington Post</td>\n",
       "      <td>cheapfast.com</td>\n",
       "      <td>discount.com</td>\n",
       "      <td>Fast Repair</td>\n",
       "      <td>staples.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acqCountry</th>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merchantCountryCode</th>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>posEntryMode</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>posConditionCode</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merchantCategoryCode</th>\n",
       "      <td>subscriptions</td>\n",
       "      <td>online_retail</td>\n",
       "      <td>online_retail</td>\n",
       "      <td>auto</td>\n",
       "      <td>online_retail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transactionType</th>\n",
       "      <td>PURCHASE</td>\n",
       "      <td>PURCHASE</td>\n",
       "      <td>PURCHASE</td>\n",
       "      <td>ADDRESS_VERIFICATION</td>\n",
       "      <td>PURCHASE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cardPresent</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expirationDateKeyInMatch</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isFraud</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CVVMatch</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>containsCom</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lengthOfLast4Digits</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creditLimitCategory</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transactionAmountBoxcox</th>\n",
       "      <td>6.36526</td>\n",
       "      <td>10.3485</td>\n",
       "      <td>9.3434</td>\n",
       "      <td>0.756828</td>\n",
       "      <td>4.99394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availableMoneyBoxcox</th>\n",
       "      <td>55.8143</td>\n",
       "      <td>43.5689</td>\n",
       "      <td>36.001</td>\n",
       "      <td>24.2871</td>\n",
       "      <td>11.9213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>currentBalanceBoxcox</th>\n",
       "      <td>0.756828</td>\n",
       "      <td>0.756828</td>\n",
       "      <td>0.756828</td>\n",
       "      <td>0.756828</td>\n",
       "      <td>0.756828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transactionTime</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transactionMonth</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dayOfTransaction</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expiryYear</th>\n",
       "      <td>2028</td>\n",
       "      <td>2023</td>\n",
       "      <td>2025</td>\n",
       "      <td>2026</td>\n",
       "      <td>2032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expiryMonth</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accountOpenYear</th>\n",
       "      <td>2015</td>\n",
       "      <td>2013</td>\n",
       "      <td>2014</td>\n",
       "      <td>2013</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accountOpenMonth</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yearOfLastAddressChange</th>\n",
       "      <td>2015</td>\n",
       "      <td>2013</td>\n",
       "      <td>2014</td>\n",
       "      <td>2013</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        0              1              2  \\\n",
       "creditLimit                         50000          20000          10000   \n",
       "availableMoney                      50000          20000          10000   \n",
       "merchantName              Washington Post  cheapfast.com   discount.com   \n",
       "acqCountry                             US             US             US   \n",
       "merchantCountryCode                    US             US             US   \n",
       "posEntryMode                            9              5              2   \n",
       "posConditionCode                        1              1              8   \n",
       "merchantCategoryCode        subscriptions  online_retail  online_retail   \n",
       "transactionType                  PURCHASE       PURCHASE       PURCHASE   \n",
       "cardPresent                         False          False          False   \n",
       "expirationDateKeyInMatch            False          False          False   \n",
       "isFraud                             False          False          False   \n",
       "CVVMatch                             True           True           True   \n",
       "containsCom                         False           True           True   \n",
       "lengthOfLast4Digits                     4              4              4   \n",
       "creditLimitCategory                     5              4              3   \n",
       "transactionAmountBoxcox           6.36526        10.3485         9.3434   \n",
       "availableMoneyBoxcox              55.8143        43.5689         36.001   \n",
       "currentBalanceBoxcox             0.756828       0.756828       0.756828   \n",
       "transactionTime                         0              0              0   \n",
       "transactionMonth                        1              1              1   \n",
       "dayOfTransaction                        4              4              4   \n",
       "expiryYear                           2028           2023           2025   \n",
       "expiryMonth                             3              4              7   \n",
       "accountOpenYear                      2015           2013           2014   \n",
       "accountOpenMonth                        5              7             10   \n",
       "yearOfLastAddressChange              2015           2013           2014   \n",
       "\n",
       "                                             3              4  \n",
       "creditLimit                               2500            250  \n",
       "availableMoney                            2500            250  \n",
       "merchantName                       Fast Repair    staples.com  \n",
       "acqCountry                                  US             US  \n",
       "merchantCountryCode                         US             US  \n",
       "posEntryMode                                 5              5  \n",
       "posConditionCode                             1              1  \n",
       "merchantCategoryCode                      auto  online_retail  \n",
       "transactionType           ADDRESS_VERIFICATION       PURCHASE  \n",
       "cardPresent                              False          False  \n",
       "expirationDateKeyInMatch                 False          False  \n",
       "isFraud                                  False          False  \n",
       "CVVMatch                                  True           True  \n",
       "containsCom                              False           True  \n",
       "lengthOfLast4Digits                          4              4  \n",
       "creditLimitCategory                          2              1  \n",
       "transactionAmountBoxcox               0.756828        4.99394  \n",
       "availableMoneyBoxcox                   24.2871        11.9213  \n",
       "currentBalanceBoxcox                  0.756828       0.756828  \n",
       "transactionTime                              0              0  \n",
       "transactionMonth                             1              1  \n",
       "dayOfTransaction                             4              4  \n",
       "expiryYear                                2026           2032  \n",
       "expiryMonth                                 12              5  \n",
       "accountOpenYear                           2013           2012  \n",
       "accountOpenMonth                            12              5  \n",
       "yearOfLastAddressChange                   2013           2012  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/transaction_data_cleaned.csv')\n",
    "print(df.shape)\n",
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using seaborns countplot to show distribution of fraud in dataset\n",
    "fig, ax = plt.subplots()\n",
    "g = sns.countplot(x=df.isFraud, palette='viridis')\n",
    "g.set_xticklabels(['Not Fraud', 'Fraud'])\n",
    "g.set_yticklabels([])\n",
    "\n",
    "# function to show values on bars\n",
    "def show_values_on_bars(axs):\n",
    "    def _show_on_single_plot(ax):        \n",
    "        for p in ax.patches:\n",
    "            _x = p.get_x() + p.get_width() / 2\n",
    "            _y = p.get_y() + p.get_height()\n",
    "            value = '{:.0f}'.format(p.get_height())\n",
    "            ax.text(_x, _y, value, ha=\"center\") \n",
    "\n",
    "    if isinstance(axs, np.ndarray):\n",
    "        for idx, ax in np.ndenumerate(axs):\n",
    "            _show_on_single_plot(ax)\n",
    "    else:\n",
    "        _show_on_single_plot(axs)\n",
    "show_values_on_bars(ax)\n",
    "\n",
    "sns.despine(left=True, bottom=True)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.title('Distribution of Transactions', fontsize=20)\n",
    "plt.tick_params(axis='x', which='major', labelsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a very imbalanced data as we have noted during our cleaning process. We will need to change our scoring metric. That is, we should not use accuracy score since we will get a high accuracy score even if we just predict that all of our transactions are not fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Train/Test Split<a id='3._Train/Test_Split'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AMC                 35235\n",
       "EZ Putt Putt        28655\n",
       "Uber                23372\n",
       "Lyft                23294\n",
       "alibaba.com         15653\n",
       "                    ...  \n",
       "TMobile Wireless       47\n",
       "Verizon Wireless       45\n",
       "ATT                    44\n",
       "Duane Reed             28\n",
       "My Fitness              7\n",
       "Name: merchantName, Length: 205, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.merchantName.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "creditLimit                 float64\n",
       "availableMoney              float64\n",
       "merchantName                 object\n",
       "acqCountry                   object\n",
       "merchantCountryCode          object\n",
       "posEntryMode                  int64\n",
       "posConditionCode              int64\n",
       "merchantCategoryCode         object\n",
       "transactionType              object\n",
       "cardPresent                    bool\n",
       "expirationDateKeyInMatch       bool\n",
       "isFraud                        bool\n",
       "CVVMatch                       bool\n",
       "containsCom                    bool\n",
       "lengthOfLast4Digits           int64\n",
       "creditLimitCategory           int64\n",
       "transactionAmountBoxcox     float64\n",
       "availableMoneyBoxcox        float64\n",
       "currentBalanceBoxcox        float64\n",
       "transactionTime               int64\n",
       "transactionMonth              int64\n",
       "dayOfTransaction              int64\n",
       "expiryYear                    int64\n",
       "expiryMonth                   int64\n",
       "accountOpenYear               int64\n",
       "accountOpenMonth              int64\n",
       "yearOfLastAddressChange       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double check data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "creditLimit                 0\n",
       "availableMoney              0\n",
       "merchantName                0\n",
       "acqCountry                  0\n",
       "merchantCountryCode         0\n",
       "posEntryMode                0\n",
       "posConditionCode            0\n",
       "merchantCategoryCode        0\n",
       "transactionType             0\n",
       "cardPresent                 0\n",
       "expirationDateKeyInMatch    0\n",
       "isFraud                     0\n",
       "CVVMatch                    0\n",
       "containsCom                 0\n",
       "lengthOfLast4Digits         0\n",
       "creditLimitCategory         0\n",
       "transactionAmountBoxcox     0\n",
       "availableMoneyBoxcox        0\n",
       "currentBalanceBoxcox        0\n",
       "transactionTime             0\n",
       "transactionMonth            0\n",
       "dayOfTransaction            0\n",
       "expiryYear                  0\n",
       "expiryMonth                 0\n",
       "accountOpenYear             0\n",
       "accountOpenMonth            0\n",
       "yearOfLastAddressChange     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only take the first 100000 rows to test. delete this line later\n",
    "df = df.sample(n = 150000) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It simply creates additional features based on the number of unique values in the categorical feature. Every unique value in the category will be added as a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creditLimit</th>\n",
       "      <th>availableMoney</th>\n",
       "      <th>posEntryMode</th>\n",
       "      <th>posConditionCode</th>\n",
       "      <th>cardPresent</th>\n",
       "      <th>expirationDateKeyInMatch</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>CVVMatch</th>\n",
       "      <th>containsCom</th>\n",
       "      <th>lengthOfLast4Digits</th>\n",
       "      <th>...</th>\n",
       "      <th>merchantName_ikea.com</th>\n",
       "      <th>merchantName_netflix.com</th>\n",
       "      <th>merchantName_oldnavy.com</th>\n",
       "      <th>merchantName_pottery-barn.com</th>\n",
       "      <th>merchantName_sears.com</th>\n",
       "      <th>merchantName_staples.com</th>\n",
       "      <th>merchantName_target.com</th>\n",
       "      <th>merchantName_walmart.com</th>\n",
       "      <th>merchantName_westelm.com</th>\n",
       "      <th>merchantName_williamssonoma.com</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>137635</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>43692.01</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99588</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>1553.54</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290964</th>\n",
       "      <td>7500.0</td>\n",
       "      <td>7500.00</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290124</th>\n",
       "      <td>2500.0</td>\n",
       "      <td>1170.98</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542895</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>49960.12</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612140</th>\n",
       "      <td>15000.0</td>\n",
       "      <td>14175.26</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428542</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>866.69</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617236</th>\n",
       "      <td>500.0</td>\n",
       "      <td>250.97</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621543</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>17494.84</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92419</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>36363.57</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        creditLimit  availableMoney  posEntryMode  posConditionCode  \\\n",
       "137635      50000.0        43692.01             9                 1   \n",
       "99588        5000.0         1553.54             9                 8   \n",
       "290964       7500.0         7500.00             9                 8   \n",
       "290124       2500.0         1170.98             5                 1   \n",
       "542895      50000.0        49960.12             9                 1   \n",
       "...             ...             ...           ...               ...   \n",
       "612140      15000.0        14175.26            90                 1   \n",
       "428542       5000.0          866.69             2                 1   \n",
       "617236        500.0          250.97             5                 1   \n",
       "621543      50000.0        17494.84             5                 1   \n",
       "92419       50000.0        36363.57             5                 1   \n",
       "\n",
       "        cardPresent  expirationDateKeyInMatch  isFraud  CVVMatch  containsCom  \\\n",
       "137635         True                     False    False      True        False   \n",
       "99588         False                     False    False      True        False   \n",
       "290964        False                     False    False      True        False   \n",
       "290124         True                     False    False      True        False   \n",
       "542895         True                     False    False      True        False   \n",
       "...             ...                       ...      ...       ...          ...   \n",
       "612140         True                     False    False      True        False   \n",
       "428542        False                     False    False      True        False   \n",
       "617236        False                     False    False      True         True   \n",
       "621543        False                     False    False      True        False   \n",
       "92419         False                     False    False      True        False   \n",
       "\n",
       "        lengthOfLast4Digits  ...  merchantName_ikea.com  \\\n",
       "137635                    4  ...                      0   \n",
       "99588                     4  ...                      0   \n",
       "290964                    4  ...                      0   \n",
       "290124                    4  ...                      0   \n",
       "542895                    4  ...                      0   \n",
       "...                     ...  ...                    ...   \n",
       "612140                    4  ...                      0   \n",
       "428542                    4  ...                      0   \n",
       "617236                    4  ...                      0   \n",
       "621543                    4  ...                      0   \n",
       "92419                     4  ...                      0   \n",
       "\n",
       "        merchantName_netflix.com  merchantName_oldnavy.com  \\\n",
       "137635                         0                         0   \n",
       "99588                          0                         0   \n",
       "290964                         0                         0   \n",
       "290124                         0                         0   \n",
       "542895                         0                         0   \n",
       "...                          ...                       ...   \n",
       "612140                         0                         0   \n",
       "428542                         0                         0   \n",
       "617236                         0                         0   \n",
       "621543                         0                         0   \n",
       "92419                          0                         0   \n",
       "\n",
       "        merchantName_pottery-barn.com  merchantName_sears.com  \\\n",
       "137635                              0                       0   \n",
       "99588                               0                       0   \n",
       "290964                              0                       0   \n",
       "290124                              0                       0   \n",
       "542895                              0                       0   \n",
       "...                               ...                     ...   \n",
       "612140                              0                       0   \n",
       "428542                              0                       0   \n",
       "617236                              0                       1   \n",
       "621543                              0                       0   \n",
       "92419                               0                       0   \n",
       "\n",
       "        merchantName_staples.com  merchantName_target.com  \\\n",
       "137635                         0                        0   \n",
       "99588                          0                        0   \n",
       "290964                         0                        0   \n",
       "290124                         0                        0   \n",
       "542895                         0                        0   \n",
       "...                          ...                      ...   \n",
       "612140                         0                        0   \n",
       "428542                         0                        0   \n",
       "617236                         0                        0   \n",
       "621543                         0                        0   \n",
       "92419                          0                        0   \n",
       "\n",
       "        merchantName_walmart.com  merchantName_westelm.com  \\\n",
       "137635                         0                         0   \n",
       "99588                          0                         0   \n",
       "290964                         0                         0   \n",
       "290124                         0                         0   \n",
       "542895                         0                         0   \n",
       "...                          ...                       ...   \n",
       "612140                         0                         0   \n",
       "428542                         0                         0   \n",
       "617236                         0                         0   \n",
       "621543                         0                         0   \n",
       "92419                          0                         0   \n",
       "\n",
       "        merchantName_williamssonoma.com  \n",
       "137635                                0  \n",
       "99588                                 0  \n",
       "290964                                0  \n",
       "290124                                0  \n",
       "542895                                0  \n",
       "...                                 ...  \n",
       "612140                                0  \n",
       "428542                                0  \n",
       "617236                                0  \n",
       "621543                                0  \n",
       "92419                                 0  \n",
       "\n",
       "[150000 rows x 256 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_cols = ['acqCountry','merchantCategoryCode','merchantCountryCode','transactionType','merchantName']\n",
    "df = pd.get_dummies(df, columns = dummy_cols)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop column with variance of 0. That is column with all the same values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X is everything but the target variable\n",
    "\n",
    "X = df.drop(columns = 'isFraud')\n",
    "selector = VarianceThreshold(threshold = 0)\n",
    "selector.fit_transform(X)\n",
    "y = df.isFraud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7500.0, 1911.59, 80, ..., 0, 0, 0],\n",
       "       [2500.0, 1738.71, 9, ..., 0, 0, 0],\n",
       "       [15000.0, 10169.06, 80, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [2500.0, 283.69, 2, ..., 0, 0, 0],\n",
       "       [2500.0, 2431.12, 9, ..., 0, 0, 0],\n",
       "       [50000.0, 43322.22, 9, ..., 0, 0, 0]], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. use train test split method\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=47)\n",
    "\n",
    "\n",
    "# 2. Variance threshold on Xtrain\n",
    "selector = VarianceThreshold(threshold = 0)\n",
    "selector.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((105000, 255), (45000, 255))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "creditLimit                        float64\n",
       "availableMoney                     float64\n",
       "posEntryMode                         int64\n",
       "posConditionCode                     int64\n",
       "cardPresent                           bool\n",
       "                                    ...   \n",
       "merchantName_staples.com             uint8\n",
       "merchantName_target.com              uint8\n",
       "merchantName_walmart.com             uint8\n",
       "merchantName_westelm.com             uint8\n",
       "merchantName_williamssonoma.com      uint8\n",
       "Length: 255, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes\n",
    "# Question 2: different data types is ok?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for extreme Multicolinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dummy Variable Trap leads to the problem known as multicollinearity. Multicollinearity occurs where there is a dependency between the independent features. Multicollinearity is a serious issue in machine learning models like Linear Regression and Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the common ways to check for multicollinearity is the Variance Inflation Factor (VIF):\n",
    "\n",
    "- VIF=1, Very Less Multicollinearity\n",
    "- VIF<5, Moderate Multicollinearity\n",
    "- VIF>5, Extreme Multicollinearity (This is what we have to avoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# def calc_vif(X):\n",
    "\n",
    "#     # Calculating VIF\n",
    "#     vif = pd.DataFrame()\n",
    "#     vif[\"variables\"] = X.columns\n",
    "#     vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "#     return(vif)\n",
    "\n",
    "# calc_vif(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Scaling<a id='4._Scaling'></a>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scale data to prepare for model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.82410738e-01, -4.89432168e-01,  4.24319114e+00, ...,\n",
       "        -1.47035413e-01, -2.39114050e-02, -2.24725792e-02],\n",
       "       [-7.09576285e-01, -5.08932075e-01, -4.92961828e-04, ...,\n",
       "        -1.47035413e-01, -2.39114050e-02, -2.24725792e-02],\n",
       "       [ 3.58337583e-01,  4.41964734e-01,  4.24319114e+00, ...,\n",
       "        -1.47035413e-01, -2.39114050e-02, -2.24725792e-02],\n",
       "       ...,\n",
       "       [-7.09576285e-01, -6.73050276e-01, -4.18884352e-01, ...,\n",
       "        -1.47035413e-01, -2.39114050e-02, -2.24725792e-02],\n",
       "       [-7.09576285e-01, -4.30832060e-01, -4.92961828e-04, ...,\n",
       "        -1.47035413e-01, -2.39114050e-02, -2.24725792e-02],\n",
       "       [ 3.34849641e+00,  4.18145765e+00, -4.92961828e-04, ...,\n",
       "        -1.47035413e-01, -2.39114050e-02, -2.24725792e-02]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #1. Call the StandardScaler`s fit method on `X_tr` to fit the scaler\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "# 2.Transform the actual X_train and X_test data to be standard normal\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 3. Variance threshold on Xtrain_scaled\n",
    "selector = VarianceThreshold(threshold = 0)\n",
    "selector.fit_transform(X_train_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Logisitic Model<a id='5._Logistic_Model'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Train test<a id='5.1_Train_test'></a>\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sherlyhartono/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9845333333333334\n",
      "roc_auc score:  0.7336826505377683\n",
      "recall:  0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# check score on the test data\n",
    "print(\"accuracy: \",accuracy_score(y_test, clf.predict(X_test_scaled)))\n",
    "print(\"roc_auc score: \",roc_auc_score(y_test, clf.predict_proba(X_test_scaled)[:,1]))\n",
    "print(\"recall: \",recall_score(y_test, clf.predict(X_test_scaled)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44304</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>696</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1\n",
       "0  44304  0\n",
       "1    696  0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix \n",
    "pd.DataFrame(confusion_matrix(y_test, clf.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a very good accuracy even without setting the parameter. This is because of the imbalance data. \n",
    "We are predicting that everything is not fraud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Tune the Model<a id='5.2_Tuning'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets tune the model to take into account the imbalanceness and see if we can get higher f1_score. In Logistic Regression, the most important parameter to tune is the regularization parameter C. Note that the regularization parameter is not always part of the logistic regression model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the following cross_val_score function to perform K-fold cross-validation and apply a scoring function to each test fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sherlyhartono/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from numpy import mean\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# prepare the cross-validation procedure\n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each C:\n",
    "1. Create a logistic regression model with that value of C\n",
    "2. Find the average score: roc_auc, recall, accuracy for this model using the cross_val_score function **only on the training set** (X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning 1: class_weight = 'balanced'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C : 0.001\n",
      "roc_auc\n",
      "0.7414561498695544\n",
      "recall\n",
      "0.6992707487015555\n",
      "\n",
      "\n",
      "C : 0.1\n",
      "roc_auc\n",
      "0.740544654493407\n",
      "recall\n",
      "0.7005103289829058\n",
      "\n",
      "\n",
      "C : 10\n",
      "roc_auc\n",
      "0.7402377976208625\n",
      "recall\n",
      "0.7005103289829058\n",
      "\n",
      "\n",
      "C : 100\n",
      "roc_auc\n",
      "0.740221407010586\n",
      "recall\n",
      "0.7011073439082789\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We need to binarize y_train if we want to do recall scoring on cross_val_score\n",
    "from sklearn import preprocessing\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit_transform(y_train)\n",
    "\n",
    "\n",
    "scores_type = ['roc_auc', 'recall']\n",
    "Cs = [0.001, 0.1, 10, 100]\n",
    "max_score = 0\n",
    "for C in Cs:\n",
    "        # 1.we pass in C as the argument for regularization parameter C\n",
    "        clf = LogisticRegression(C = C, class_weight = \"balanced\" )\n",
    "        \n",
    "        print(\"C :\",C)\n",
    "        for score_type in scores_type:\n",
    "            # 2. take the score of the model above\n",
    "            # print \n",
    "            print(score_type) \n",
    "            mean_score = mean(cross_val_score(clf, X_train_scaled, y_train, scoring = score_type, cv=cv, n_jobs=-1))\n",
    "            print(mean_score)\n",
    "        \n",
    "        print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At C=0.001 we have the highest ROC_AUC score and recall score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning 2: Oversampled data\n",
    "#### Let's try oversampled data to see if this changes our Logistic Regression performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({False: 103373, True: 103119})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "from collections import Counter\n",
    "\n",
    "ada = ADASYN(random_state=42)\n",
    "\n",
    "# 1. get oversampled data\n",
    "X_ada, y_ada = ada.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# 2. check new class distribution\n",
    "print(Counter(y_ada))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Create new Logistic model\n",
    "# We don't need to add argument for weight_score since we are doing this manually\n",
    "clf = LogisticRegression(C=0.001)\n",
    "\n",
    "# # 2. train on the balanced oversampled data\n",
    "clf.fit(X_ada, y_ada)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oversampling recall score:  0.6594827586206896\n",
      "Oversampling ROC_AUC score:  0.7173263849972812\n"
     ]
    }
   ],
   "source": [
    "# scores on the test data\n",
    "print('Oversampling recall score: ', \n",
    "      recall_score(y_test, clf.predict(X_test_scaled)))\n",
    "\n",
    "print('Oversampling ROC_AUC score: ', \n",
    "      roc_auc_score(y_test, clf.predict_proba(X_test_scaled)[:,1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is worse than what we get above!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning 3: Undersampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({False: 1627, True: 1627})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# instantiating the random undersampler\n",
    "rus = RandomUnderSampler() \n",
    "\n",
    "# resampling X, y\n",
    "X_rus, y_rus = rus.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# new class distribution\n",
    "print(Counter(y_rus))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling set Recall:  0.7480024585125998\n",
      "Undersampling ROC_AUC score:  0.755753433611155\n"
     ]
    }
   ],
   "source": [
    "# Create new Logistic model and train on the balanced undersampled data\n",
    "# lb.fit(y_rus)\n",
    "clf3 = LogisticRegression(C=0.001)\n",
    "clf3.fit(X_rus, y_rus)\n",
    "\n",
    "# check recall score on training data\n",
    "print('Undersampling set Recall: ', \n",
    "      recall_score(y_train, clf3.predict(X_train_scaled)))\n",
    "\n",
    "print('Undersampling ROC_AUC score: ', \n",
    "      roc_auc_score(y_train, clf3.predict_proba(X_train_scaled)[:,1]))\n",
    "\n",
    "print('mean_train3',mean(cross_val_score(clf3, X, y, scoring = 'recall', cv=cv, n_jobs=-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undersampling gives a much better score on test data. Lets try this again after our GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Pipeline<a id='5.3_Pipeline'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.1 Define the pipeline with RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import make_pipeline as make_pipeline_imb\n",
    "pipe_imb = make_pipeline_imb(StandardScaler(),RandomUnderSampler(),LogisticRegression())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.2 Fit the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_imb.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check list of estimator for gridCV\n",
    "pipe_imb.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Refine Model using GridSearchCV<a id='5.4_Refine'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.4.1 Create grid<a id='5.4.1_Create_Grid'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which scoring should we use?\n",
    "\n",
    "With highly imbalance data and when there is a high cost associated with False Negative (Fraud but classified as not fraud) we use Recall.\n",
    "Recall calculates how many of the Actual Positives(Fraud) our model capture through labeling it as Positive (Truly Fraud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/recall.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solvers = ['liblinear', 'newton-cg', 'lbfgs']\n",
    "penalty = ['l2']\n",
    "c_values = [0.001, 0.1, 100]\n",
    "\n",
    "grid = dict(logisticregression__solver = solvers,\n",
    "            logisticregression__penalty = penalty,\n",
    "            logisticregression__C = c_values)\n",
    "\n",
    "grid_search = GridSearchCV(pipe_imb, param_grid=grid, n_jobs=-1, cv=cv, scoring='average_precision_score',error_score=0)\n",
    "\n",
    "grid_result = grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.4.2 Summarize Results<a id='5.4.2_Summarize_Result'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.4.3 Check best params<a id='5.4.3_Check_best_params'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# See if best C is the same as before gridCvShttp://localhost:8890/notebooks/CreditCardFraud/PreprocessingTraining.ipynb#earch\n",
    "grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Predict and get scores for the test datas <a id='5.5_Recreate_model'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall score is the number of true positives divided by the number of positive values in the test data. Recall is also called Sensitivity or the True Positive Rate. It is a measure of a classifier's completeness. Low recall indicates a high number of false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Scaled data with class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C = 0.001,\n",
    "                         penalty = 'l2',\n",
    "                         solver = 'liblinear',\n",
    "                         class_weight = \"balanced\")\n",
    "\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 3. predict\n",
    "y_test_pred_weight = clf.predict(X_test_scaled)\n",
    "\n",
    "# 4. calculate accuracy\n",
    "roc_auc = roc_auc_score(y_test, clf.predict_proba(X_test_scaled)[:,1])\n",
    "recall = recall_score(y_test, y_test_pred_weight)\n",
    "\n",
    "print(\"roc_auc: \",roc_auc)\n",
    "print(\"recall: \",recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Undersampled Test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "clf2 = LogisticRegression(C = 0.001,\n",
    "                         penalty = 'l2',\n",
    "                         solver = 'liblinear' )\n",
    "\n",
    "\n",
    "# 2. fit the model using oversampled data.\n",
    "clf2.fit(X_rus, y_rus)\n",
    "\n",
    "# 3. predict\n",
    "y_test_pred_rus = clf2.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "# 4. calculate accuracy\n",
    "roc_auc = roc_auc_score(y_test, clf2.predict_proba(X_test_scaled)[:,1])\n",
    "recall = recall_score(y_test, y_test_pred_rus)\n",
    "\n",
    "\n",
    "print(\"roc_auc: \",roc_auc)\n",
    "print(\"recall: \",recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_test_pred_rus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undersampling data gives a much better recall score thant using original scaled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare with **Training score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. predict\n",
    "y_train_pred_rus = clf2.predict(X_train_scaled)\n",
    "\n",
    "# 2. calculate accuracy\n",
    "roc_auc = roc_auc_score(y_train, clf2.predict_proba(X_train_scaled)[:,1])\n",
    "recall = recall_score(y_train, y_train_pred_rus)\n",
    "\n",
    "print(\"roc_auc: \",roc_auc)\n",
    "print(\"recall: \",recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is not much difference between test and  train prediction. We can keep this model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Confusion matrix with best params<a id='5.6_Confusion_matrix'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define plot confusion matrix function\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Confusion Matrix Result trained on data with class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute confusion matrix and plot. Check if its making better prediction\n",
    "cm = confusion_matrix(y_test, y_test_pred_weight)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix for 'Survived'\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm, classes=['isFraud'],\n",
    "                      title='Confusion matrix class_weight = balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Confusion Matrix Result trained on undersampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm2 = confusion_matrix(y_test, y_test_pred_rus)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix for 'Survived'\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm2, classes=['isFraud'],\n",
    "                      title='Confusion matrix Undersampled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the false negative is much lower in undersampled data (152) compared to oversampled data (201). Although the false positive is higher in the undersampled data (20400) vs oversampled (15965)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7 ROC/AUC Score<a id='5.7_ROC_AUC'></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, plot_precision_recall_curve\n",
    "# Calculate ROC for the model\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "\n",
    "# 1. predict probabilities for test data\n",
    "# (kind of like getting the the proportion)\n",
    "probs = clf2.predict_proba(X_test_scaled)\n",
    "\n",
    "# 2. keep probabilities of positive class only\n",
    "preds = probs[:,1]\n",
    "\n",
    "# 3. get ROC curve\n",
    "fpr, tpr, threshold = roc_curve(y_test, preds)\n",
    "\n",
    "# 4. compute AUC score\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot roc function\n",
    "def plot_roc_curve(fpr,tpr):\n",
    "    #title\n",
    "    plt.title('Receiver Operating Characteristic (Undersampled data model)')\n",
    "    \n",
    "    # plot curve\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    \n",
    "    # plot fpr=tpr \n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    \n",
    "    #limit\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    \n",
    "    #label\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(fpr,tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision-Recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision1, recall1, thresholds1 = precision_recall_curve(ytest, preds)\n",
    "\n",
    "# get precision recall auc score\n",
    "precision_recall_auc1 = auc(recall1, precision1)\n",
    "plt.plot(recall1, precision1, label = 'LogisticRegression = %0.3f' % precision_recall_auc1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC score is fair. Let's see if we can improve uisng Random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Random Forest Model<a id='6._Random_Forest_Model'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Train Test<a id='6.1_Train_test'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new model trained on Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# 1. create new pipeline for random forest classifier including downscaling\n",
    "imba_pipeline = make_pipeline(RandomUnderSampler(),\n",
    "                              StandardScaler(),\n",
    "                              RandomForestClassifier())\n",
    "\n",
    "# 2. get score\n",
    "cross_val_score(imba_pipeline, X_train, y_train, scoring='roc_auc', cv=cv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Refining model using RandomSearchCV<a id='6.3_Refine'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many parameters to tune. How do we start?\n",
    "- n_estimators = number of trees in the forest\n",
    "- max_features = max number of features considered for splitting a node\n",
    "- max_depth = max number of levels in each decision tree\n",
    "- min_samples_split = min number of data points placed in a node before the node is split\n",
    "- min_samples_leaf = min number of data points allowed in a leaf node\n",
    "- bootstrap = method for sampling data points (with or without replacement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets used randomized search CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.1 Create Grid<a id='6.3.1_Create_Grid'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# 1. Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 50, stop = 500, num = 4)]\n",
    "\n",
    "# 2. Number of features to consider at every split\n",
    "\n",
    "\n",
    "# 3. Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(2, 15, num = 4)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# 4. Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# 5. Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [ 2, 5, 10]\n",
    "\n",
    "# 6. Method of selecting samples for training each tree\n",
    "bootstrap = [True]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap,\n",
    "               'class_weight': ['balanced']}\n",
    "print(random_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf,\n",
    "                               param_distributions = random_grid,\n",
    "                               n_iter = 20, cv = 5,\n",
    "                               verbose=2,\n",
    "                               scoring='roc_auc',\n",
    "                               random_state=42,\n",
    "                               n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.2 Check best params<a id='6.3.2_Check_best_params'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print winning set of hyperparameters\n",
    "from pprint import pprint\n",
    "pprint(rf_random.best_estimator_.get_params())\n",
    "pprint(rf_random.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Recreate model with best param<a id='6.4_Recreate_model'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best = rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 ROC/AUC Score<a id='6.5_ROC_AUC'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROC for the model\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "\n",
    "# 1. predict probabilities for test data\n",
    "# (kind of like getting the the proportion)\n",
    "probs = rf_best.predict_proba(X_test_scaled)\n",
    "\n",
    "# 2. keep probabilities of positive class only\n",
    "preds = probs[:,1]\n",
    "\n",
    "# 3. get ROC curve\n",
    "fpr2, tpr2, threshold = roc_curve(y_test, preds)\n",
    "\n",
    "# 4. compute AUC score\n",
    "roc_auc2 = auc(fpr2, tpr2)\n",
    "plt.plot(fpr2, tpr2, 'b', label = 'AUC = %0.2f' % roc_auc2)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.legend(loc = 'lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We significantly increased our AUC scored compared to our previous logistic regression model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. XG Boost Model<a id='7_XG_Boost_Model'></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Train Test<a id='7.1_Train_test'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train 1: use scale_pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take into account imbalance data by modifying scale_pos_weight\n",
    "clf_xg = xgb.XGBClassifier(scale_pos_weight=100)\n",
    "clf_xg.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check performance before tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Train \n",
    "# print roc_auc and recall score for training data\n",
    "print('Train score')\n",
    "print('Training recall score: ', \n",
    "      recall_score(y_train, clf_xg.predict(X_train_scaled)))\n",
    "\n",
    "print('Training ROC_AUC score: ', \n",
    "      roc_auc_score(y_train, clf.predict_proba(X_train_scaled)[:,1]))\n",
    "\n",
    "\n",
    "# 2. Test\n",
    "print('Test score')\n",
    "print('Test recall score: ', \n",
    "      recall_score(y_test, clf_xg.predict(X_test_scaled)))\n",
    "\n",
    "print('Test ROC_AUC score: ', \n",
    "      roc_auc_score(y_test, clf.predict_proba(X_test_scaled)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is huge difference between train and test score , it is overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check cross validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_train = mean(cross_val_score(clf_xg, X_train_scaled, y_train, scoring = 'roc_auc', cv=cv, n_jobs=-1))\n",
    "# print('roc_auc scale pos weight', mean_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train 2: use undersampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xg_rus = xgb.XGBClassifier()\n",
    "clf_xg_rus.fit(X_rus, y_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print roc_auc score for training data\n",
    "\n",
    "cross_val_score(clf_xg_rus, X, y, scoring = 'roc_auc', cv=cv, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using undersampled data result in lower performance for training data but better performance on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Refining model using RandomSearch<a id='7.2_Refine'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2.1 Create Grid<a id='7.2.1_Create_Grid'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xg =xgb.XGBClassifier(tree_method = \"exact\", predictor = \"cpu_predictor\", verbosity=1,\n",
    "                        objective='binary:logistic')\n",
    "\n",
    "# Create parameter grid\n",
    "parameters = {\"scale_pos_weight\" : [1, 25, 50, 75, 99],\n",
    "              \"learning_rate\": [0.1, 0.01, 0.001],\n",
    "              \"gamma\" : [0.01, 0.1, 0.3, 0.5, 1, 1.5, 2],\n",
    "              \"max_depth\": [2, 4, 7, 10],\n",
    "              \"colsample_bytree\": [0.3, 0.6, 0.8, 1.0],\n",
    "              \"subsample\": [0.2, 0.4, 0.5, 0.6, 0.7],\n",
    "              \"reg_alpha\": [0, 0.5, 1],\n",
    "              \"reg_lambda\": [1, 1.5, 2, 3, 4.5],\n",
    "              \"min_child_weight\": [1, 3, 5, 7],\n",
    "              \"n_estimators\": [100, 1000, 1500, 2000]\n",
    "             }\n",
    "\n",
    "# n_estimators: 2000, 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RandomizedSearchCV Object\n",
    "xgb_rscv = RandomizedSearchCV(clf_xg, param_distributions = parameters, scoring = \"roc_auc\",\n",
    "                             cv = 5, verbose = 3, random_state = 40, n_jobs =-1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model_xgboost = xgb_rscv.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2.2 Check Best Params<a id='7.2.2_Check_best_params'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question: why is interaction contraints empty\n",
    "# get best score\n",
    "pprint(model_xgboost.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pprint(model_xgboost.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Recreate model with best param<a id='7.3_Recreate_model'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.create model \n",
    "xg_best = model_xgboost.best_estimator_\n",
    "\n",
    "# 2. predict\n",
    "y_pred = xg_best.predict_proba(X_test_scaled)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. predict probabilities for test data\n",
    "# # (kind of like getting the the proportion)\n",
    "# probs = rf_best.predict_proba(X_test_scaled)\n",
    "\n",
    "# # 2. keep probabilities of positive class only\n",
    "# preds = probs[:,1]\n",
    "\n",
    "# # 3. get ROC curve\n",
    "# fpr2, tpr2, threshold = roc_curve(y_test, preds)\n",
    "\n",
    "# # 4. compute AUC score\n",
    "# roc_auc2 = auc(fpr2, tpr2)\n",
    "# plt.plot(fpr2, tpr2, 'b', label = 'AUC = %0.2f' % roc_auc2)\n",
    "# plt.plot([0, 1], [0, 1],'r--')\n",
    "# plt.legend(loc = 'lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 ROC/AUC Score<a id='7.4_ROC_AUC'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. get ROC curve\n",
    "fpr3, tpr3, threshold = roc_curve(y_test, y_pred)\n",
    "\n",
    "# 4. compute AUC score\n",
    "roc_auc3 = auc(fpr3, tpr3)\n",
    "plot_roc_curve(fpr3,tpr3)\n",
    "\n",
    "roc_auc3 = roc_auc_score(y_test, y_pred)\n",
    "print('roc_auc best', roc_auc3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its performing worse than random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try another classifier trained on undersampled data using best param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_undersampled = xgb.XGBClassifier(\n",
    "     base_score = 0.5,\n",
    "     booster= 'gbtree',\n",
    "     colsample_bylevel= 1,\n",
    "     colsample_bynode= 1,\n",
    "     colsample_bytree= 1.0,\n",
    "     gamma= 2,\n",
    "     gpu_id= -1,\n",
    "     importance_type= 'gain',\n",
    "     learning_rate= 0.1,\n",
    "     max_delta_step= 0,\n",
    "     max_depth= 2,\n",
    "     min_child_weight= 5,\n",
    "     monotone_constraints= (),\n",
    "     n_estimators= 500,\n",
    "     n_jobs= 0,\n",
    "     num_parallel_tree= 1,\n",
    "     objective= 'binary:logistic',\n",
    "     predictor= 'cpu_predictor',\n",
    "     random_state= 0,\n",
    "     reg_alpha= 0,\n",
    "     reg_lambda= 4.5,\n",
    "     scale_pos_weight= 75,\n",
    "     subsample= 0.5,\n",
    "     tree_method= 'exact',\n",
    "     validate_parameters= 1,\n",
    "     verbosity= 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_undersampled.fit(X_rus, y_rus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_undersampled.predict_proba(X_test_scaled)[:,1]\n",
    "roc_auc_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It still doesnt do as well as RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "plt.title('Receiver Operating Characteristic Comparison', size=20)\n",
    "plt.plot(fpr, tpr, label = 'LogReg = %0.3f' % roc_auc)\n",
    "plt.plot(fpr2, tpr2, label = 'RandomForest = %0.3f' % roc_auc2)\n",
    "plt.plot(fpr3, tpr3, label = 'XgBoost = %0.3f' % roc_auc3)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.legend(title='AUC', loc = 'lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.Series(rf_best.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "_ = plt.figure(figsize=(12,7))\n",
    "_ = sns.barplot(x=feature_imp[:10], y=feature_imp[:10].index)\n",
    "_ = plt.xlabel('Feature Importance Score')\n",
    "_ = plt.ylabel('Features')\n",
    "_ = plt.title('Visualizing Important Features', size=20)\n",
    "_ = plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Learning Curve<a id='8._Learning_Curve'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Would more data be useful? We're often led to believe more data is always good, but gathering data invariably has a cost associated with it. Assess this trade off by seeing how performance varies with differing data set sizes. The learning_curve function does this conveniently.\n",
    "\n",
    "A learning curve shows the validation and training score of an estimator for varying numbers of training samples. It is a tool to find out how much we benefit from adding more training data and whether the estimator suffers more from a variance error or a bias error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fractions = [.2, .25, .3, .35, .4, .45, .5, .6, .75, .8, 1.0]\n",
    "train_size, train_scores, test_scores = learning_curve(xg_best, X_train, y_train, train_sizes=fractions)\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(10, 5))\n",
    "plt.errorbar(train_size, test_scores_mean, yerr=test_scores_std)\n",
    "plt.xlabel('Training set size')\n",
    "plt.ylabel('CV scores')\n",
    "plt.title('Cross-validation score as training set size increases');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Save Model<a id='9._Save_Model'></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code task 28#\n",
    "#This may not be \"production grade ML deployment\" practice, but adding some basic\n",
    "#information to your saved models can save your bacon in development.\n",
    "#Just what version model have you just loaded to reuse? What version of `sklearn`\n",
    "#created it? When did you make it?\n",
    "#Assign the pandas version number (`pd.__version__`) to the `pandas_version` attribute,\n",
    "#the numpy version (`np.__version__`) to the `numpy_version` attribute,\n",
    "#the sklearn version (`sklearn_version`) to the `sklearn_version` attribute,\n",
    "#and the current datetime (`datetime.datetime.now()`) to the `build_datetime` attribute\n",
    "#Let's call this model version '1.0'\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import datetime\n",
    "from sklearn import __version__ as sklearn_version\n",
    "\n",
    "best_model = xg_best\n",
    "best_model.version ='1.0'\n",
    "best_model.pandas_version = pd.__version__\n",
    "best_model.numpy_version = np.__version__\n",
    "best_model.sklearn_version = sklearn_version\n",
    "best_model.X_columns = [col for col in X_train.columns]\n",
    "best_model.build_datetime = datetime.datetime.now()\n",
    "    \n",
    "modelpath = '../CreditCardFraud/models'\n",
    "if not os.path.exists(modelpath):\n",
    "    os.mkdir(modelpath)\n",
    "    \n",
    "fraud_prediction_path = os.path.join(modelpath, 'fraud_prediction_model.pkl')\n",
    "if not os.path.exists(fraud_prediction_path):\n",
    "    with open(fraud_prediction_path, 'wb') as f:\n",
    "        pickle.dump(best_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
