{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Contents<a id='Contents'></a>\n",
    "* [1. Imports](#1._Imports)\n",
    "* [2. Convert txt file to data frame](#2._Convert_txt_file_to_data_frame)\n",
    "* [3. Clean empty values](#3._Clean)\n",
    "* [4. Data Types Problem](#4._Data_Types)\n",
    "* [5. Profiling](#5._Profiling)\n",
    "* [6. Drop columns](#6._Drop_columns)\n",
    "* [7. Explore the Data](#7._Explore_Data)\n",
    "    * [7.1. Date Time Features](#7._Date_Time)\n",
    "    * [7.2. Categorical Features](#7._Categorical)\n",
    "    * [7.3. Numerical Features](#7._Numerical)\n",
    "* [8. Save Data](#8._Save)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports <a id='1._Imports'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "from pandas_profiling import ProfileReport\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Convert txt file to data frame<a id='2._Convert_txt_file_to_data_frame'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/47889565/reading-json-objects-from-text-file-into-pandas\n",
    "\n",
    "list = []\n",
    "with open('transactions.txt') as file:\n",
    "    for line in file:\n",
    "        list.append(json.loads(line)) #convert each line to json then add to list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = pd.DataFrame(list) # convert this list into panda data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clean empty values<a id='3._Clean'></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# too big cut to half use iloc for slicing on index\n",
    "transactions = transactions.iloc[50000:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace empty string with Nan\n",
    "transactions_Nan = transactions.replace('', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all Nan column\n",
    "transactions_dropped = transactions_Nan.dropna(how='all',axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if successfuly dropped\n",
    "# 6 columns have been dropped\n",
    "transactions_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many Nan values in each column\n",
    "transactions_dropped.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with any Nan\n",
    "transactions_dropped = transactions_dropped.dropna(how = 'any', axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check no Nan values on any row\n",
    "transactions_dropped.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Types Problem<a id='4._Data_Types'></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if all the data are in a usable form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_dropped.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Change Datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can change date entries to date time objects. That is the column:\n",
    "1. transactionDateTime\n",
    "2. currentExpDate\n",
    "3. accountOpenDate\n",
    "4. dateOfLastAddressChange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_change = ['transactionDateTime','currentExpDate','accountOpenDate','dateOfLastAddressChange']\n",
    "for column in columns_to_change:\n",
    "#     transactions_dropped.loc[:,column] = pd.to_datetime(transactions_dropped[column])\n",
    "    transactions_dropped.loc[:,column] = pd.to_datetime(transactions_dropped[column].copy())\n",
    "# pd.to_datetime takes series as argument\n",
    "# dont need to do loc on the assignment RHS\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cannot do:\n",
    "# 1. transactions_dropped.loc[:,column] = transactions_dropped.loc[:,column].apply(pd.to_datetime, errors = 'coerce')\n",
    "\n",
    "# 2. for column in columns_to_change:\n",
    "#     transactions_dropped[column] = pd.to_datetime(transactions_dropped[column])\n",
    "\n",
    "#     transactions_dropped.loc[:,column] = pd.to_datetime(transactions_dropped.loc[:,column])\n",
    "# the key is put pd.to_datetime at the front. and also do .loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_dropped.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Profiling<a id='5._Profiling'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(transactions_dropped, title = 'Profile Report')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Profiling Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Total Fraud: \n",
    "\n",
    "    - Only 11513 out of 756363 of transactions are fraud, which means only 1.5% are fraudulent. This is very small.\n",
    "\n",
    "2. Date type:\n",
    "\n",
    "    - Everything looks normal: Transaction starts from January 2016 to December 30th\n",
    "\n",
    "\n",
    "3. Categorical:\n",
    "\n",
    "    - Account number\n",
    "    - customerID: looks like its identical to account number\n",
    "    - transaction type: Does fraud occur in transaction type other than purchase ? if not, we can get rid of it\n",
    "    - merchantName: check for duplicates\n",
    "    - cardLast4Digits: some only has 2 digits, does this mean fraud?\n",
    "\n",
    "\n",
    "4. Numerical:\n",
    "\n",
    "    - Balance:\n",
    "    Need to deal with zeros and extreme values\n",
    "\n",
    "    - Transaction amount: \n",
    "There seems to be a high correlation between transaction amount and fraudulence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Drop columns<a id='6._Drop_columns'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above profiling it seems like there are no duplicate rows, but lets check for duplicate columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Duplicate column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Check if customer Id is the same as account number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(transactions_dropped['customerId']==transactions_dropped['accountNumber']).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The true entry count is the same as total number of rows, they are the same. so let's remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_dropped = transactions_dropped.drop(columns='customerId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Check if acqCountry is the same as merchant countrycode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(transactions_dropped['acqCountry']==transactions_dropped['merchantCountryCode']).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "not necessarily the same. so lets not remove them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Check if cardCVV is the same as enteredCVV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_dropped[(transactions_dropped['cardCVV']!=transactions_dropped['enteredCVV'])].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are 6676 unmatched CVV. We cannot drop them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. It may be useful to create a column of 'CVV match'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_dropped['CVVMatch'] = transactions_dropped['cardCVV'] == transactions_dropped['enteredCVV']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop enteredCVV and card CVV since we already have matched CVV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_dropped = transactions_dropped.drop(columns=['enteredCVV','cardCVV'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Useless column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reset index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transactions_dropped.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 Explore Data Entries<a id='7._Explore_Data'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Datetime Features <a id='7._Date_Time'></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1.1 Check if it has healthy distribution. no outliers\n",
    "\n",
    "What do I need to change about date time ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(3,2,figsize = (15,15))\n",
    "fraud_transactions = transactions_dropped[transactions_dropped.isFraud == True]\n",
    "fraud_transactions\n",
    "fraud_transactions= fraud_transactions.sort_values('transactionDateTime',ascending=True)\n",
    "transactions= transactions_dropped.sort_values('transactionDateTime',ascending=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3,2,figsize = (15,15))\n",
    "\n",
    "# Fraud (1st column)\n",
    "axs[0][0].hist(fraud_transactions['transactionDateTime'], bins = 20)\n",
    "axs[0][0].set_xlabel('Transaction Date')\n",
    "axs[0][0].set_title('Fraud')\n",
    "\n",
    "axs[1][0].hist(fraud_transactions['dateOfLastAddressChange'], bins = 20)\n",
    "axs[1][0].set_xlabel('Last Date of Address Change')\n",
    "axs[1][0].set_title('Fraud')\n",
    "\n",
    "\n",
    "axs[2][0].hist(fraud_transactions['accountOpenDate'], bins = 20)\n",
    "axs[2][0].set_xlabel('accountOpenDate')\n",
    "axs[2][0].set_title('Fraud')\n",
    "\n",
    "# # Not Fraud (2nd Column)\n",
    "axs[0][1].hist(transactions['transactionDateTime'], bins = 50)\n",
    "axs[0][1].set_xlabel('Transaction Date')\n",
    "axs[0][1].set_title('Not Fraud')\n",
    "\n",
    "axs[1][1].hist(transactions['dateOfLastAddressChange'], bins = 50)\n",
    "axs[1][1].set_xlabel('Last Date of Address Change')\n",
    "axs[1][1].set_title('Not Fraud')\n",
    "\n",
    "axs[2][1].hist(transactions['accountOpenDate'], bins = 50)\n",
    "axs[2][1].set_xlabel('accountOpenDate')\n",
    "axs[2][1].set_title('Not Fraud')\n",
    "\n",
    "# Rotate x value \n",
    "for ax in fig.axes:\n",
    "    plt.sca(ax)\n",
    "    plt.xticks(rotation =90)\n",
    "    \n",
    "plt.subplots_adjust(hspace = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like a healthy distribution no outliers. Transaction is between January 2016 to Dec 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Categorical Features <a id='7._Categorical'></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2.1 Merchant Name\n",
    "\n",
    "Check if there is any duplicate that are mistype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check the top fraud merchant names\n",
    "fraud_transactions.merchantName.value_counts().head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there are many branches of the same company. Should we combine them together ?\n",
    "Lets check how many EZ Putt Putt are there\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_transactions[fraud_transactions.merchantName.str.contains('EZ') == True].merchantName.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_transactions[fraud_transactions.merchantName.str.contains('AMC') == True].merchantName.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_transactions[fraud_transactions.merchantName.str.contains('Hardee') == True].merchantName.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets get rid of this column and possibly put all franchise under one name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "separator = '#'\n",
    "transactions['merchantName'] = [merchant_name.split(separator,1)[0].rstrip() for merchant_name in transactions['merchantName']]\n",
    "# for each merchant name in transaction, split them in two using separator '#'. take the first element of the split\n",
    "# strip the last empty space\n",
    "\n",
    "transactions['merchantName'].str.contains('#').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same with fraud transactions\n",
    "fraud_transactions = transactions[transactions.isFraud ==True]\n",
    "fraud_transactions['merchantName'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are alot of '.com' lets check how many .com are fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_transactions['merchantName'].str.contains('.com').value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are more than half of fraud have .com in it. We could use this to make a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_transactions.loc[:,'containsCom'] = fraud_transactions['merchantName'].str.contains('.com').copy()\n",
    "transactions.loc[:,'containsCom'] = transactions.loc[:,'merchantName'].str.contains('.com').copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### 7.2.2 Transaction Type\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does fraud occur in transaction type other than purchase?\n",
    "fraud_transactions['transactionType'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all fraud transaction are Purchase so we need to keep this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2.3 Card last 4 digits.\n",
    "\n",
    "What do we do with only 2 digits or anything not 4?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions[transactions['cardLast4Digits'].str.len() < 4].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many rows with string card last 4 digits less than\n",
    "4. Lets keep this, the number of digits might give us some insights. It might be more useful to make a new variable that tells us the length of the digits than the actual number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions['lengthOfLast4Digits'] = transactions['cardLast4Digits'].str.len()\n",
    "transactions['lengthOfLast4Digits'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove card last 4 digits column\n",
    "transactions = transactions.drop(columns = 'cardLast4Digits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2.4 Pos Entry Mode\n",
    "\n",
    "\n",
    "09 PAN entry via electronic commerce, including chip.\n",
    "\n",
    "02 Magnetic stripe read. For Plus transactions, this code also means    that the exact Track 2 content is included and CVV checking is        possible.\n",
    "\n",
    "05 Integrated circuit card read; card data reliable.\n",
    "\n",
    "90 Magnetic stripe read and extract content of Track 1 or Track 2 included (CVV check is possible).\n",
    "\n",
    "80 Chip card was unable to process/magnetic stripe read default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions['posEntryMode'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything make sense. No faulty entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2.5 Post Condition Code\n",
    "\n",
    "\n",
    "01 - Cardholder not present\n",
    "\n",
    "08 - Mail/telephone order (includes Visa phone and reoccurring transactions)\n",
    "\n",
    "99 - Doesnt exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions['posConditionCode'].value_counts()\n",
    "# make new feature for 99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code 99 doesnt exist. Should we replace with other code? Lets check what are the transaction with code 99. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transactions[transactions['posConditionCode'] == '99'].merchantName.value_counts().head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2.6 Country\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check if merchant country code is the same as acqCOuntry entry\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(transactions.acqCountry == transactions.merchantCountryCode).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "64 have countries that don't match. How many of these are fraud ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions[(transactions.acqCountry != transactions.merchantCountryCode)].isFraud.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of them are not fraud. What about the ones that have match countries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions[transactions.acqCountry == transactions.merchantCountryCode].isFraud.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whent the country is the same, there is more chance that is Fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Numerical Features <a id='7._Numerical'></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3.1 Check for Zeros Transaction amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_transactions[fraud_transactions['transactionAmount']==0].transactionType.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the transaction types are address verification when transactiont amount is zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3.2 Check for distribution in credit card limit at 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many transactions using credit card with limit of 50,000 are fraud? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(transactions[transactions['creditLimit']==50000]['isFraud']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  get the percentage\n",
    "789/ (44973+789) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 1.72% of credit card with limit of 50,000 is fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the credit cards that are not 50,000. what are the percentages that are fraud?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(transactions[transactions['creditLimit']!=50000]['isFraud']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  get the percentage\n",
    "10522/ (670998+10522) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.54% of credit card with limit of not 50,000 is fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are about the same. so eventhough the cc limit is high, it only increase its fraud possibility by 0.2%\n",
    "Should we keep this cc limit of 50,000?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the fraud/not fraud for each cc limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limitArray = fraud_transactions['creditLimit'].unique().sort()\n",
    "\n",
    "fraud_transactions['creditLimit'].hist(figsize=(5,5))\n",
    "plt.title('FRAUD ONLY Transactions')\n",
    "plt.xlabel('cc limit $')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions['creditLimit'].hist(figsize=(5,5))\n",
    "plt.title('All Transactions')\n",
    "plt.xlabel('cc limit $')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do Z proportion test to check if the proportion is actually different ?\n",
    "Lets reduce the number of unique values to 8 instead of 10. We can treat this entry as categorical instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions['creditLimit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    (transactions['creditLimit'] <= 1000.0),\n",
    "    (transactions['creditLimit'] >= 2500.0) & (transactions['creditLimit'] <= 5000.0),\n",
    "    (transactions['creditLimit'] >= 7500.0) & (transactions['creditLimit'] <= 10000.0),\n",
    "    (transactions['creditLimit'] >= 15000.0)& (transactions['creditLimit'] <= 20000.0) ,\n",
    "    (transactions['creditLimit'] == 50000.0)]\n",
    "# 1- '1000 and below'\n",
    "# 2- '2500-5000'\n",
    "# 3- '7500-10000'\n",
    "# 4- 15000-20000'\n",
    "# 5-'50000 and over'\n",
    "choices = [1, 2,3,4,5]\n",
    "transactions['creditLimitCategory'] = np.select(conditions,choices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pandas. plot to plot bar\n",
    "# .sort_index make sure its not sorted according to the value\n",
    "\n",
    "transactions['creditLimitCategory'].value_counts().sort_index(axis=0).plot(kind='bar', rot = 0, x = 'category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative, use matplot lib plt.bar()\n",
    "labels, counts = np.unique(transactions['creditLimitCategory'],return_counts = True)\n",
    "plt.bar(labels, counts, align= 'center')\n",
    "plt.gca().set_xticks(labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 Save Data<a id='8._Save'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '../CreditCardFraud/data'\n",
    "# renaming the output data directory and re-running this notebook, for example,\n",
    "# will recreate this (empty) directory 'data' and resave the data files.\n",
    "\n",
    "# NB this is not a substitute for a modern data pipeline, for which there are\n",
    "# various tools. However, for our purposes here, and often in a \"one off\" analysis,\n",
    "# this is useful because we have to deliberately move/delete our data in order\n",
    "# to overwrite it.\n",
    "\n",
    "#if path doesnt exist\n",
    "if not os.path.exists(datapath):\n",
    "    #create data path\n",
    "    os.mkdir(datapath)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath_transactiondata = os.path.join(datapath, 'transaction_data_cleaned.csv')\n",
    "\n",
    "transactions.to_csv(datapath_transactiondata, index=False)\n",
    "print(datapath_transactiondata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/transaction_data_cleaned.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
